{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai gradio transformers sentencepiece --quiet\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "client = OpenAI(api_key=\"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\")# Replace with your actual key\")  # Replace with your actual API key\n",
        "\n",
        "# Hugging Face fallback model\n",
        "hf_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# for uploding the file\n",
        "def read_file(file_obj):\n",
        "    \"\"\"Read uploaded file content safely.\"\"\"\n",
        "    if file_obj is None:\n",
        "        return \"\"\n",
        "    try:\n",
        "        # Gradio now passes a temporary file path, not raw bytes\n",
        "        with open(file_obj.name, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read()\n",
        "    except Exception as e:\n",
        "        return f\"Error reading file: {e}\"\n",
        "def summarize(text, style):\n",
        "    if not text.strip():\n",
        "        return \"Error: provide text or file.\"\n",
        "\n",
        "    # Summarization prompt\n",
        "    prompts = {\n",
        "        \"Brief\": f\"Summarize briefly:\\n\\n{text}\",\n",
        "        \"Detailed\": f\"Summarize in detail:\\n\\n{text}\",\n",
        "        \"Bullet Points\": f\"Summarize as bullet points:\\n\\n{text}\",\n",
        "    }\n",
        "    prompt = prompts.get(style, f\"Summarize the following text:\\n\\n{text}\")\n",
        "    ## for handling the error\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful summarization assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        summary = response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ OpenAI API Error:\", e)\n",
        "        if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "            print(\"➡️ Switching to Hugging Face fallback model...\")\n",
        "            try:\n",
        "                hf_summary = hf_summarizer(text, max_length=180, min_length=40, do_sample=False)\n",
        "                summary = hf_summary[0]['summary_text']\n",
        "            except Exception as hf_error:\n",
        "                summary = f\"Error using fallback model: {hf_error}\"\n",
        "        else:\n",
        "            summary = \"Error: \" + str(e)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=lambda text, file, style: summarize(text or read_file(file), style),\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=20, placeholder=\"Paste your text...\", label=\"Text Input\"),\n",
        "        gr.File(label=\"Or upload a text file\"),\n",
        "        gr.Dropdown([\"Brief\", \"Detailed\", \"Bullet Points\"], value=\"Brief\", label=\"Summarization Style\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Summary\"),\n",
        "    title=\"Smart Document Summarizer\",\n",
        "    description=\"Automatically uses GPT-3.5 if available; switches to Hugging Face if OpenAI quota runs out.\"\n",
        ")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "9EZ-mA70Jev0",
        "outputId": "e6e0f6ed-b420-42c8-c14e-d2d57110ab18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://776830d33098ef04f4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://776830d33098ef04f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekPVArhkJfpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}